{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1 - Predicción de precios de vehículos usados\n",
    "\n",
    "En este proyecto podrán poner en práctica sus conocimientos sobre modelos predictivos basados en árboles y ensambles, y sobre la disponibilización de modelos. Para su desasrrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 1: Predicción de precios de vehículos usados\".\n",
    "\n",
    "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 4. Sin embargo, es importante que avancen en la semana 3 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
    "\n",
    "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 4, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/t/4bd64c1deb3c4ffb8ca7ff93c1f1497d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos para la predicción de precios de vehículos usados\n",
    "\n",
    "En este proyecto se usará el conjunto de datos de Car Listings de Kaggle, donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como: año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo predicción conjunto de test para envío a Kaggle\n",
    "\n",
    "En esta sección encontrarán el formato en el que deben guardar los resultados de la predicción para que puedan subirlos a la competencia en Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xg\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import joblib\n",
    "import werkzeug\n",
    "from werkzeug.utils import cached_property\n",
    "from flask import Flask\n",
    "\n",
    "try:\n",
    "    from flask_restplus import Api, Resource, fields\n",
    "except ImportError:\n",
    "    import werkzeug\n",
    "    werkzeug.cached_property = werkzeug.utils.cached_property\n",
    "    from flask_restplus import Resource, Api, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "dataTraining = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTotal = dataTraining.loc[:,dataTraining.columns!=\"Price\"]\n",
    "yTotal = dataTraining.loc[:,dataTraining.columns==\"Price\"]\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(XTotal, yTotal, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Buscamos valores Nulos en las variables.\n",
    "XTrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['Year'].describe())\n",
    "XTrain['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['Mileage'].describe())\n",
    "XTrain['Mileage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['State'].describe())\n",
    "XTrain['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['Make'].describe())\n",
    "XTrain['Make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['Model'].describe())\n",
    "XTrain['Model'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.State = XTrain.State.str.replace(' ', '')\n",
    "XTrain['YearsBetween']=2022-XTrain['Year']\n",
    "XTrain['MileagebyYear']=XTrain['Mileage']/XTrain['YearsBetween']\n",
    "State=pd.get_dummies(XTrain[\"State\"], prefix='State')\n",
    "XTrain=pd.concat([XTrain, State], axis=1)\n",
    "Make=pd.get_dummies(XTrain[\"Make\"], prefix='Make')\n",
    "XTrain=pd.concat([XTrain, Make], axis=1)\n",
    "Model=pd.get_dummies(XTrain[\"Model\"], prefix='Model')\n",
    "XTrain=pd.concat([XTrain, Model], axis=1)\n",
    "\n",
    "XTrain=XTrain.drop([\"State\",\"Make\",\"Model\",\"Make_Freightliner\"], axis=1)\n",
    "#ss = StandardScaler()\n",
    "#XTrain = ss.fit_transform(XTrain)\n",
    "XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XTest.State = XTest.State.str.replace(' ', '')\n",
    "XTest['YearsBetween']=2022-XTest['Year']\n",
    "XTest['MileagebyYear']=XTest['Mileage']/XTest['YearsBetween']\n",
    "State=pd.get_dummies(XTest[\"State\"], prefix='State')\n",
    "XTest=pd.concat([XTest, State], axis=1)\n",
    "Make=pd.get_dummies(XTest[\"Make\"], prefix='Make')\n",
    "XTest=pd.concat([XTest, Make], axis=1)\n",
    "Model=pd.get_dummies(XTest[\"Model\"], prefix='Model')\n",
    "XTest=pd.concat([XTest, Model], axis=1)\n",
    "\n",
    "XTest=XTest.drop([\"State\",\"Make\",\"Model\",\"Make_Freightliner\"], axis=1)\n",
    "#XTest = ss.transform(XTest)\n",
    "XTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de Modelo Sin Calibración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation\n",
    "xgb_r = xg.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.1, learning_rate = 0.1, max_depth = 5, verbosity = 0)\n",
    "\n",
    "# Fitting the model\n",
    "xgb_r.fit(XTrain, yTrain)\n",
    "  \n",
    "# Predict the model\n",
    "pred = xgb_r.predict(XTest)\n",
    "  \n",
    "# RMSE Computation\n",
    "rmse_base = np.sqrt(MSE(yTest, pred))\n",
    "print(\"RMSE : % f\" %(rmse_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de Calibración\n",
    "\n",
    "### ¡Advertencia!\n",
    "### Este proceso puede tomar más de 4hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate calibration\n",
    "\n",
    "learning_rate_range = np.linspace(0.01, 0.5, num=10)\n",
    "accuracy_scores = []\n",
    "\n",
    "for learning_rate in learning_rate_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=learning_rate, verbosity = 0 )\n",
    "\n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(learning_rate,rmse)\n",
    "plt.plot(learning_rate_range, accuracy_scores)\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n",
    "print(\" Alcanzamos el minimo RMSE con learning_rate = \" + str(learning_rate_range[np.argmin(accuracy_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma calibration\n",
    "gamma_range = np.linspace(0.01, 0.5, num=10)\n",
    "accuracy_scores = []\n",
    "for gamma in gamma_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5,gamma=gamma, verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(gamma,rmse)\n",
    "    \n",
    "plt.plot(gamma_range, accuracy_scores)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n",
    "print(\" Alcanzamos el minimo RMSE con gamma = \" + str(gamma_range[np.argmin(accuracy_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colsample_bytree calibration\n",
    "colsample_bytree_range = np.linspace(0.01, 0.5, num=10)\n",
    "accuracy_scores = []\n",
    "for colsample_bytree in colsample_bytree_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective ='reg:linear',learning_rate=0.5 ,gamma=0.01, colsample_bytree=colsample_bytree, verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(colsample_bytree,rmse)\n",
    "    \n",
    "print(colsample_bytree_range[np.argmin(accuracy_scores)])\n",
    "plt.plot(colsample_bytree_range, accuracy_scores)\n",
    "plt.xlabel('colsample_bytree')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colsample_bytree calibration\n",
    "max_depth_range = estimator_range = range(1, 10)\n",
    "\n",
    "accuracy_scores = []\n",
    "for max_depth in max_depth_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5 ,gamma=0.01, colsample_bytree=0.5,max_depth=max_depth, verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(max_depth,rmse)\n",
    "    \n",
    "print(max_depth_range[np.argmin(accuracy_scores)])\n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colsample_bytree calibration\n",
    "alpha_range = estimator_range = range(1, 10)\n",
    "\n",
    "\n",
    "accuracy_scores = []\n",
    "for alpha in alpha_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5 ,gamma=0.01, colsample_bytree=0.5,max_depth=max_depth,alpha=alpha ,verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(alpha,rmse)\n",
    "    \n",
    "print(max_depth_range[np.argmin(accuracy_scores)])\n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar  Modelo Calibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo calibrado\n",
    "clf = xg.XGBRegressor(learning_rate=0.5,gamma=0.01, colsample_bytree=0.5, max_depth=9,alpha=1,verbosity = 0 )    \n",
    "# Fitting the model\n",
    "clf.fit(XTrain, yTrain)\n",
    "# Predict the model\n",
    "pred = clf.predict(XTest)\n",
    "# RMSE Computation\n",
    "rmse_cal=np.sqrt(MSE(yTest, pred))\n",
    "print('RMSE:',rmse_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el Modelo Calibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar modelo a archivo binario .pkl\n",
    "joblib.dump(clf, 'modelo_precio_autos_calibrado.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar modelo y predicción\n",
    "from predice_precio_model_deployment import predice_precio\n",
    "\n",
    "# Predicción de precio  de  un auto\n",
    "predice_precio(2017,9913,'FL','Jeep','Wrangler') \n",
    "#34995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_title(\"Comparación de Tiempos de Ejecución entre Modelos (RMSE)\")\n",
    "ejeX = ['XGBoost','XGBoost Cal.']\n",
    "ejeY = [float(round(rmse_base,4)),float(round(rmse_cal,4))]\n",
    "ax.bar(ejeX,ejeY)\n",
    "def addlabels(x,y,plotP):\n",
    "    for i in range(len(x)):\n",
    "        plotP.text(i,y[i],y[i])\n",
    "addlabels(ejeX,ejeY,plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfilando datos de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de test\n",
    "dataTesting = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTest_carListings.zip', index_col=0)\n",
    "dataTesting['YearsBetween']=2022-dataTesting['Year']\n",
    "dataTesting['MileagebyYear']=dataTesting['Mileage']/dataTesting['YearsBetween']\n",
    "State=pd.get_dummies(dataTesting[\"State\"], prefix='State')\n",
    "dataTesting=pd.concat([dataTesting, State], axis=1)\n",
    "Make=pd.get_dummies(dataTesting[\"Make\"], prefix='Make')\n",
    "dataTesting=pd.concat([dataTesting, Make], axis=1)\n",
    "Model=pd.get_dummies(dataTesting[\"Model\"], prefix='Model')\n",
    "dataTesting=pd.concat([dataTesting, Model], axis=1)\n",
    "\n",
    "dataTesting=dataTesting.drop([\"State\",\"Make\",\"Model\"], axis=1)\n",
    "pred = clf.predict(dataTesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "yPred=pd.DataFrame(pred,columns=['Price'])\n",
    "# Exportamos a un archivo los resultados\n",
    "yPred.to_csv('test_submission.csv', index_label='ID')\n",
    "yPred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disponibilizar modelo con Flask\n",
    "\n",
    "Para esta sección del notebook instale las siguientes librerías *!pip install flask* y *!pip install flask_restplus*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predice_precio_model_deployment import predice_precio\n",
    "\n",
    "# Definición aplicación Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Definición API Flask\n",
    "api = Api(\n",
    "    app, \n",
    "    version='1.0', \n",
    "    title='API de Predicción de Precios de Autos',\n",
    "    description='API de Predicción de Precios de Autos')\n",
    "\n",
    "ns = api.namespace('predict', \n",
    "     description='Regresión de Precio de Auto')\n",
    "\n",
    "# Definición argumentos o parámetros de la API\n",
    "parser = api.parser()\n",
    "\n",
    "parser.add_argument(\n",
    "    'Year', \n",
    "    type=int, \n",
    "    required=True, \n",
    "    help='Año del modelo', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'Mileage', \n",
    "    type=int, \n",
    "    required=True, \n",
    "    help='Millas recorridas', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'State', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Estado de procedencia', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'Make', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Marca de la ensambladora de auto', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'Model', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Sub marca del auto', \n",
    "    location='args')\n",
    "\n",
    "resource_fields = api.model('Resource', {\n",
    "    'result': fields.String,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la clase para disponibilización\n",
    "@ns.route('/')\n",
    "class PhishingApi(Resource):\n",
    "\n",
    "    @api.doc(parser=parser)\n",
    "    @api.marshal_with(resource_fields)\n",
    "    def get(self):\n",
    "        args = parser.parse_args()\n",
    "        print(args)\n",
    "        return {\n",
    "         \"result\": predice_precio(args['Year'],args['Mileage'],args['State'],args['Make'],args['Model'])\n",
    "        }, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5002/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [26/Apr/2022 18:30:17] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2022 18:30:17] \"\u001b[37mGET /swagger.json HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2022 18:30:53] \"\u001b[37mGET /predict/?Year=2017&Mileage=1983&State=FL&Make=Jeep&Model=Wrangler HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Year': 2017, 'Mileage': 1983, 'State': 'FL', 'Make': 'Jeep', 'Model': 'Wrangler'}\n"
     ]
    }
   ],
   "source": [
    "# Ejecución de la aplicación que disponibiliza el modelo de manera local en el puerto 5000\n",
    "app.run(debug=True, use_reloader=False, host='0.0.0.0', port=5002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
