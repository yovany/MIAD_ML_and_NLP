{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1 - Predicción de precios de vehículos usados\n",
    "\n",
    "En este proyecto podrán poner en práctica sus conocimientos sobre modelos predictivos basados en árboles y ensambles, y sobre la disponibilización de modelos. Para su desasrrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 1: Predicción de precios de vehículos usados\".\n",
    "\n",
    "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 4. Sin embargo, es importante que avancen en la semana 3 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
    "\n",
    "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 4, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/t/4bd64c1deb3c4ffb8ca7ff93c1f1497d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos para la predicción de precios de vehículos usados\n",
    "\n",
    "En este proyecto se usará el conjunto de datos de Car Listings de Kaggle, donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como: año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xg\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import joblib\n",
    "import werkzeug\n",
    "from werkzeug.utils import cached_property\n",
    "from flask import Flask\n",
    "\n",
    "try:\n",
    "    from flask_restplus import Api, Resource, fields\n",
    "except ImportError:\n",
    "    import werkzeug\n",
    "    werkzeug.cached_property = werkzeug.utils.cached_property\n",
    "    from flask_restplus import Resource, Api, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "dataTraining = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTotal = dataTraining.loc[:,dataTraining.columns!=\"Price\"]\n",
    "yTotal = dataTraining.loc[:,dataTraining.columns==\"Price\"]\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(XTotal, yTotal, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Buscamos valores Nulos en las variables.\n",
    "XTrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['Year'].describe())\n",
    "XTrain['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['Mileage'].describe())\n",
    "XTrain['Mileage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['State'].describe())\n",
    "XTrain['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['Make'].describe())\n",
    "XTrain['Make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain['Model'].describe())\n",
    "XTrain['Model'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.State = XTrain.State.str.replace(' ', '')\n",
    "XTrain['YearsBetween']=2022-XTrain['Year']\n",
    "XTrain['MileagebyYear']=XTrain['Mileage']/XTrain['YearsBetween']\n",
    "State=pd.get_dummies(XTrain[\"State\"], prefix='State')\n",
    "XTrain=pd.concat([XTrain, State], axis=1)\n",
    "Make=pd.get_dummies(XTrain[\"Make\"], prefix='Make')\n",
    "XTrain=pd.concat([XTrain, Make], axis=1)\n",
    "Model=pd.get_dummies(XTrain[\"Model\"], prefix='Model')\n",
    "XTrain=pd.concat([XTrain, Model], axis=1)\n",
    "XTrain=XTrain.drop([\"State\",\"Make\",\"Model\",\"Make_Freightliner\"], axis=1)\n",
    "XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XTest.State = XTest.State.str.replace(' ', '')\n",
    "XTest['YearsBetween']=2022-XTest['Year']\n",
    "XTest['MileagebyYear']=XTest['Mileage']/XTest['YearsBetween']\n",
    "State=pd.get_dummies(XTest[\"State\"], prefix='State')\n",
    "XTest=pd.concat([XTest, State], axis=1)\n",
    "Make=pd.get_dummies(XTest[\"Make\"], prefix='Make')\n",
    "XTest=pd.concat([XTest, Make], axis=1)\n",
    "Model=pd.get_dummies(XTest[\"Model\"], prefix='Model')\n",
    "XTest=pd.concat([XTest, Model], axis=1)\n",
    "XTest=XTest.drop([\"State\",\"Make\",\"Model\",\"Make_Freightliner\"], axis=1)\n",
    "XTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de Modelo Sin Calibración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation\n",
    "xgb_r = xg.XGBRegressor()\n",
    "\n",
    "# Fitting the model\n",
    "xgb_r.fit(XTrain, yTrain)\n",
    "  \n",
    "# Predict the model\n",
    "pred = xgb_r.predict(XTest)\n",
    "  \n",
    "# RMSE Computation\n",
    "rmse_base = np.sqrt(MSE(yTest, pred))\n",
    "print(\"RMSE : % f\" %(rmse_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de Calibración\n",
    "\n",
    "### ¡Advertencia!\n",
    "### Este proceso puede tomar más de 4hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate calibration\n",
    "\n",
    "learning_rate_range = np.linspace(0.01, 0.5, num=10)\n",
    "accuracy_scores = []\n",
    "\n",
    "for learning_rate in learning_rate_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=learning_rate, verbosity = 0)\n",
    "\n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(learning_rate,rmse)\n",
    "plt.plot(learning_rate_range, accuracy_scores)\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n",
    "print(\" Alcanzamos el minimo RMSE con learning_rate = \" + str(learning_rate_range[np.argmin(accuracy_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gamma calibration\n",
    "gamma_range = np.linspace(0.01, 0.5, num=10)\n",
    "accuracy_scores = []\n",
    "for gamma in gamma_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5,gamma=gamma, verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(gamma,rmse)\n",
    "    \n",
    "plt.plot(gamma_range, accuracy_scores)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n",
    "print(\" Alcanzamos el minimo RMSE con gamma = \" + str(gamma_range[np.argmin(accuracy_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsample_bytree_range = np.linspace(0.01, 0.5, num=10)\n",
    "accuracy_scores = []\n",
    "for colsample_bytree in colsample_bytree_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective ='reg:linear',learning_rate=0.5 ,gamma=0.01, colsample_bytree=colsample_bytree, verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(colsample_bytree,rmse)\n",
    "    \n",
    "print(colsample_bytree_range[np.argmin(accuracy_scores)])\n",
    "plt.plot(colsample_bytree_range, accuracy_scores)\n",
    "plt.xlabel('colsample_bytree')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range  = range(5, 15,1)\n",
    "\n",
    "accuracy_scores = []\n",
    "for max_depth in max_depth_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5 ,gamma=0.01, colsample_bytree=0.5,max_depth=max_depth, verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(max_depth,rmse)\n",
    "    \n",
    "print(max_depth_range[np.argmin(accuracy_scores)])\n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range  = range(1, 10)\n",
    "\n",
    "accuracy_scores = []\n",
    "for alpha in alpha_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5 ,gamma=0.01, colsample_bytree=0.5,max_depth=13,alpha=alpha ,verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(alpha,rmse)\n",
    "    \n",
    "print(max_depth_range[np.argmin(accuracy_scores)])\n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_weight_range = range(5,15,1)\n",
    "\n",
    "accuracy_scores = []\n",
    "for min_child_weight in min_child_weight_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5 ,gamma=0.01, colsample_bytree=0.5,max_depth=13,alpha=7, min_child_weight=min_child_weight ,verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(min_child_weight,rmse)\n",
    "    \n",
    "print(min_child_weight_range[np.argmin(accuracy_scores)])\n",
    "plt.plot(min_child_weight_range, accuracy_scores)\n",
    "plt.xlabel('min_child_weight')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_range = np.linspace(0.01, 1, num=10)\n",
    "\n",
    "accuracy_scores = []\n",
    "for subsample in subsample_range:\n",
    "    \n",
    "    clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5 ,gamma=0.01, colsample_bytree=0.5,max_depth=13,alpha=7, min_child_weight=9, subsample=subsample ,verbosity = 0 )\n",
    "    \n",
    "    # Fitting the model\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    # Predict the model\n",
    "    pred = clf.predict(XTest)\n",
    "\n",
    "    # RMSE Computation\n",
    "    rmse=np.sqrt(MSE(yTest, pred))\n",
    "    accuracy_scores.append(rmse)\n",
    "    print(subsample,rmse)\n",
    "    \n",
    "print(subsample_range[np.argmin(accuracy_scores)])\n",
    "plt.plot(subsample_range, accuracy_scores)\n",
    "plt.xlabel('subsample')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round_range = range(160,170,1)\n",
    "\n",
    "housing_dmatrix = xg.DMatrix(data=XTrain, label=yTrain)\n",
    "\n",
    "# Creata the parameter dictionary for each tree: params\n",
    "params = {\"objective\":\"reg:squarederror\",\n",
    "\"learning_rate\":0.5,\n",
    "\"gamma\":0.01, \n",
    "\"colsample_bytree\":0.5, \n",
    "\"max_depth\":13,\n",
    "\"alpha\":7, \n",
    "\"min_child_weight\":11, \n",
    "\"n_estimators\":100}\n",
    "\n",
    "\n",
    "# Empty list to store final round rmse per XGBoost model\n",
    "final_rmse_per_round = []\n",
    "\n",
    "# Interate over num_rounds and build one model per num_boost_round parameter\n",
    "for curr_num_rounds in num_boost_round_range:\n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xg.cv( dtrain=housing_dmatrix,\n",
    "                       params=params, nfold=3, \n",
    "                        num_boost_round=curr_num_rounds, metrics='rmse', \n",
    "                        as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append final round RMSE\n",
    "    rmse=(cv_results['test-rmse-mean'].tail().values[-1])\n",
    "    final_rmse_per_round.append(rmse)\n",
    "    print(curr_num_rounds,rmse)\n",
    "\n",
    "print(num_boost_round_range[np.argmin(final_rmse_per_round)])\n",
    "plt.plot(num_boost_round_range, final_rmse_per_round)\n",
    "plt.xlabel('subsample')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar  Modelo Calibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo calibrado\n",
    "clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5,gamma=0.01, colsample_bytree=0.5, max_depth=13,alpha=7, min_child_weight=11,subsample=1,n_estimators=100,num_boost_round=165, verbosity = 0 )    \n",
    "# Fitting the model\n",
    "clf.fit(XTrain, yTrain)\n",
    "# Predict the model\n",
    "pred = clf.predict(XTest)\n",
    "# RMSE Computation\n",
    "rmse_cal=np.sqrt(MSE(yTest, pred))\n",
    "print('RMSE:',rmse_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficamos la importacia de la variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orden= clf.feature_importances_.argsort()\n",
    "plt.barh(XTrain.columns[orden],clf.feature_importances_[orden])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos las variables que no aportan al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice=[]\n",
    "for i in range(0,617):\n",
    "    if clf.feature_importances_[i]>0.00:\n",
    "        indice.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas=XTrain.columns[indice]\n",
    "\n",
    "XTrain=XTrain[columnas]\n",
    "XTest=XTest[columnas]\n",
    "\n",
    "print(XTrain.shape,XTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustamos el modelo con los cambios apliacado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo calibrado\n",
    "clf = xg.XGBRegressor(objective='reg:squarederror',learning_rate=0.5,gamma=0.01, colsample_bytree=0.5, max_depth=13,alpha=7, min_child_weight=9,subsample=1,n_estimators=100,num_boost_round=150, verbosity = 0 )    \n",
    "\n",
    "# Fitting the model\n",
    "clf.fit(XTrain, yTrain)\n",
    "# Predict the model\n",
    "pred = clf.predict(XTest)\n",
    "# RMSE Computation\n",
    "rmse_cal=np.sqrt(MSE(yTest, pred))\n",
    "print('RMSE:',rmse_cal)\n",
    "#3,592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orden= clf.feature_importances_.argsort()\n",
    "plt.barh(XTrain.columns[orden],clf.feature_importances_[orden])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el Modelo Calibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar modelo a archivo binario .pkl\n",
    "joblib.dump(clf, 'modelo_precio_autos_calibrado.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:35:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[08:35:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[08:35:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBModel' object has no attribute 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpredice_precio_model_deployment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predice_precio\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Predicción de precio  de  un auto\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mpredice_precio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2017\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9913\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mJeep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWrangler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\MIAD_ML_and_NLP\\Semana 3\\predice_precio_model_deployment.py:577\u001b[0m, in \u001b[0;36mpredice_precio\u001b[1;34m(year, mileage, state, make, model)\u001b[0m\n\u001b[0;32m    574\u001b[0m valores_modelo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mmodel]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m prediccion \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalores_modelo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediccion\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1047\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1043\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m _convert_ntree_limit(\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster(), ntree_limit, iteration_range\n\u001b[0;32m   1045\u001b[0m )\n\u001b[0;32m   1046\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iteration_range(iteration_range)\n\u001b[1;32m-> 1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_can_use_inplace_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1050\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1051\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1055\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1056\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:983\u001b[0m, in \u001b[0;36mXGBModel._can_use_inplace_predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_can_use_inplace_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;66;03m# When predictor is explicitly set, using `inplace_predict` might result into\u001b[39;00m\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;66;03m# error with incompatible data type.\u001b[39;00m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;66;03m# Inplace predict doesn't handle as many data types as DMatrix, but it's\u001b[39;00m\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;66;03m# sufficient for dask interface where input is simpiler.\u001b[39;00m\n\u001b[1;32m--> 983\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predictor \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:636\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    634\u001b[0m cp \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    635\u001b[0m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 636\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# if kwargs is a dict, update params accordingly\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:633\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"Get parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# Based on: https://stackoverflow.com/questions/59248211\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# The basic flow in `get_params` is:\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# 0. Return parameters in subclass first, by using inspect.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# 1. Return parameters in `XGBModel` (the base class).\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# 2. Return whatever in `**kwargs`.\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# 3. Merge them.\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m cp \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    635\u001b[0m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:211\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    209\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[1;32m--> 211\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    213\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBModel' object has no attribute 'callbacks'"
     ]
    }
   ],
   "source": [
    "# Importar modelo y predicción\n",
    "from predice_precio_model_deployment import predice_precio\n",
    "\n",
    "# Predicción de precio  de  un auto\n",
    "predice_precio(2017,9913,'FL','Jeep','Wrangler') \n",
    "#34995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_title(\"Comparación de Tiempos de Ejecución entre Modelos (RMSE)\")\n",
    "ejeX = ['XGBoost','XGBoost Cal.']\n",
    "ejeY = [float(round(rmse_base,4)),float(round(rmse_cal,4))]\n",
    "ax.bar(ejeX,ejeY)\n",
    "def addlabels(x,y,plotP):\n",
    "    for i in range(len(x)):\n",
    "        plotP.text(i,y[i],y[i])\n",
    "addlabels(ejeX,ejeY,plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfilando datos de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de test\n",
    "dataTesting = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTest_carListings.zip', index_col=0)\n",
    "\n",
    "dataTesting.State = dataTesting.State.str.replace(' ', '')\n",
    "dataTesting['YearsBetween']=2022-dataTesting['Year']\n",
    "dataTesting['MileagebyYear']=dataTesting['Mileage']/dataTesting['YearsBetween']\n",
    "State=pd.get_dummies(dataTesting[\"State\"], prefix='State')\n",
    "dataTesting=pd.concat([dataTesting, State], axis=1)\n",
    "Make=pd.get_dummies(dataTesting[\"Make\"], prefix='Make')\n",
    "dataTesting=pd.concat([dataTesting, Make], axis=1)\n",
    "Model=pd.get_dummies(dataTesting[\"Model\"], prefix='Model')\n",
    "dataTesting=pd.concat([dataTesting, Model], axis=1)\n",
    "dataTesting=dataTesting.drop([\"State\",\"Make\",\"Model\"], axis=1)\n",
    "dataTesting= dataTesting[columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(dataTesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "yPred=pd.DataFrame(pred,columns=['Price'])\n",
    "# Exportamos a un archivo los resultados\n",
    "yPred.to_csv('test_submission.csv', index_label='ID')\n",
    "yPred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disponibilizar modelo con Flask\n",
    "\n",
    "Para esta sección del notebook instale las siguientes librerías *!pip install flask* y *!pip install flask_restplus*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predice_precio_model_deployment import predice_precio\n",
    "\n",
    "# Definición aplicación Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Definición API Flask\n",
    "api = Api(\n",
    "    app, \n",
    "    version='1.0', \n",
    "    title='API de Predicción de Precios de Autos',\n",
    "    description='API de Predicción de Precios de Autos')\n",
    "\n",
    "ns = api.namespace('predict', \n",
    "     description='Regresión de Precio de Auto')\n",
    "\n",
    "# Definición argumentos o parámetros de la API\n",
    "parser = api.parser()\n",
    "\n",
    "parser.add_argument(\n",
    "    'Year', \n",
    "    type=int, \n",
    "    required=True, \n",
    "    help='Año del modelo', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'Mileage', \n",
    "    type=int, \n",
    "    required=True, \n",
    "    help='Millas recorridas', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'State', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Estado de procedencia', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'Make', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Marca de la ensambladora de auto', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'Model', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Sub marca del auto', \n",
    "    location='args')\n",
    "\n",
    "resource_fields = api.model('Resource', {\n",
    "    'result': fields.String,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la clase para disponibilización\n",
    "@ns.route('/')\n",
    "class PhishingApi(Resource):\n",
    "\n",
    "    @api.doc(parser=parser)\n",
    "    @api.marshal_with(resource_fields)\n",
    "    def get(self):\n",
    "        args = parser.parse_args()\n",
    "        print(args)\n",
    "        return {\n",
    "         \"result\": predice_precio(args['Year'],args['Mileage'],args['State'],args['Make'],args['Model'])\n",
    "        }, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución de la aplicación que disponibiliza el modelo de manera local en el puerto 5000\n",
    "app.run(debug=True, use_reloader=False, host='0.0.0.0', port=5002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(alpha=7, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.5, enable_categorical=False,\n",
    "             gamma=0.01, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.5, max_delta_step=0,\n",
    "             max_depth=13, min_child_weight=9, missing=nan,\n",
    "             monotone_constraints='()', n_estimators=100, n_jobs=2, nthread=2,\n",
    "             num_parallel_tree=1, objective='reg:linear', predictor='auto',\n",
    "             random_state=0, reg_alpha=7, reg_lambda=1, scale_pos_weight=1,\n",
    "             subsample=1.0, tree_method='exact', validate_parameters=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
